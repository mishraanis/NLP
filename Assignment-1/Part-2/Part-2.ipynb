{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from utils import emotion_scores\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLM:\n",
    "    def __init__(self):\n",
    "        self.vocab = set()\n",
    "        self.bigram_counts = defaultdict(lambda: defaultdict(int))\n",
    "        self.unigram_counts = defaultdict(int)\n",
    "        self.bigram_probs = None\n",
    "        self.beta_values = None\n",
    "        self.emotion_dict = {'sadness': 0, 'joy': 1, 'love': 2, 'anger': 3, 'fear': 4, 'surprise': 5}\n",
    "        self.sentence_emotions = []\n",
    "        self.bigram_sentences = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    def learn_from_dataset(self, dataset):\n",
    "        for x, sentence in enumerate(dataset):\n",
    "            emotion = emotion_scores(sentence)\n",
    "            self.sentence_emotions.append(emotion)\n",
    "            tokens = sentence.split()                        \n",
    "            for i in range(len(tokens) - 1):\n",
    "                word1, word2 = tokens[i], tokens[i + 1]\n",
    "                self.vocab.add(word1)\n",
    "                self.vocab.add(word2)\n",
    "                self.bigram_counts[word1][word2] += 1\n",
    "                self.bigram_sentences[word1][word2].append(x)\n",
    "                self.unigram_counts[word1] += 1                            \n",
    "                \n",
    "        self.vocab = list(self.vocab)\n",
    "        print(f\"Vocabulary size: {len(self.vocab)}\")\n",
    "\n",
    "    def calculate_beta_values_sentence(self):  \n",
    "        num_words = len(self.vocab)\n",
    "        self.beta_values_sentence = np.zeros((num_words, num_words, 6))\n",
    "\n",
    "        for i, word1 in tqdm(enumerate(self.vocab)):\n",
    "            if word1 not in self.bigram_counts.keys():\n",
    "                continue\n",
    "            for j, word2 in enumerate(self.vocab):\n",
    "                if word2 not in self.bigram_counts[word1].keys():\n",
    "                    continue\n",
    "                self.beta_values_sentence[i][j] = np.array([np.mean([self.sentence_emotions[sentence][k]['score'] for sentence in self.bigram_sentences[word1][word2]]) for k in range(6)])\n",
    "                \n",
    "\n",
    "    def calculate_beta_values(self):\n",
    "            num_words = len(self.vocab)\n",
    "            self.beta_values = np.zeros((num_words, num_words, 6))\n",
    "            for i, word1 in tqdm(enumerate(self.vocab)):\n",
    "                if word1 not in self.bigram_counts.keys():\n",
    "                    continue\n",
    "                for j, word2 in enumerate(self.vocab):\n",
    "                    if word2 not in self.bigram_counts[word1].keys():\n",
    "                        continue\n",
    "                    emotions = emotion_scores(word1 + \" \" + word2)\n",
    "                    self.beta_values[i][j] = np.array([emotions[k]['score'] for k in range(6)])\n",
    "                    \n",
    "    def calculate_bigram_probs(self):\n",
    "        num_words = len(self.vocab)\n",
    "        self.bigram_probs = np.zeros((num_words, num_words))        \n",
    "        \n",
    "        for i, word1 in tqdm(enumerate(self.vocab)):\n",
    "            for j, word2 in enumerate(self.vocab):\n",
    "                if self.unigram_counts[word1] > 0:\n",
    "                    self.bigram_probs[i][j] = float(self.bigram_counts[word1][word2]) / float(self.unigram_counts[word1])\n",
    "\n",
    "                    \n",
    "    def calculate_bigram_probs_laplace(self):\n",
    "        num_words = len(self.vocab)\n",
    "        self.bigram_probs = np.zeros((num_words, num_words))\n",
    "\n",
    "        for i, word1 in enumerate(self.vocab):\n",
    "            for j, word2 in enumerate(self.vocab):\n",
    "                self.bigram_probs[i][j] = (self.bigram_counts[word1][word2] + 1) / (self.unigram_counts[word1] + num_words)\n",
    "                \n",
    "    \n",
    "    def calculate_bigram_probs_kneser_ney(self, discount=0.75):\n",
    "        num_words = len(self.vocab)\n",
    "        self.bigram_probs = np.zeros((num_words, num_words))\n",
    "\n",
    "        continuation_counts = defaultdict(set)\n",
    "   \n",
    "        for word1, word2_dict in self.bigram_counts.items():\n",
    "            for word2 in word2_dict:\n",
    "                continuation_counts[word2].add(word1)\n",
    "\n",
    "        total_continuations = {word2: len(word1s) for word2, word1s in continuation_counts.items()}\n",
    "\n",
    "        for i, word1 in tqdm(enumerate(self.vocab)):            \n",
    "            for j, word2 in enumerate(self.vocab):\n",
    "                if word2 in total_continuations.keys():\n",
    "                    adjusted_count = max(self.bigram_counts[word1][word2] - discount, 0)\n",
    "                    continuation_prob = total_continuations[word2] / sum(total_continuations.values()) if sum(total_continuations.values()) > 0 else 0\n",
    "                    lower_order_weight = (discount * continuation_prob) / self.unigram_counts[word1] if self.unigram_counts[word1] > 0 else 0\n",
    "\n",
    "                    self.bigram_probs[i][j] = adjusted_count / self.unigram_counts[word1] + lower_order_weight if self.unigram_counts[word1] > 0 else 0                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = open('../Dataset/corpus.txt')\n",
    "dataset = []\n",
    "for i in corpus.readlines():\n",
    "    dataset.append('<SOS> ' + i + ' <EOS>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 5431\n"
     ]
    }
   ],
   "source": [
    "model = BigramLM()\n",
    "model.learn_from_dataset(dataset)\n",
    "pickle.dump(model.vocab, open('Checkpoints/vocab.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.calculate_beta_values_sentence()\n",
    "pickle.dump(model.beta_values_sentence, open('Checkpoints/beta_values_sentence.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.calculate_beta_values()\n",
    "pickle.dump(model.beta_values, open('Checkpoints/beta_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5431it [00:08, 621.91it/s]\n"
     ]
    }
   ],
   "source": [
    "model.calculate_bigram_probs()\n",
    "pickle.dump(model.bigram_probs, open('Checkpoints/bigram_probs.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5431it [24:45,  3.66it/s]\n"
     ]
    }
   ],
   "source": [
    "model.calculate_bigram_probs_kneser_ney()\n",
    "pickle.dump(model.bigram_probs, open('Checkpoints/bigram_probs_kneser.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.calculate_bigram_probs_laplace()\n",
    "pickle.dump(model.bigram_probs, open('Checkpoints/bigram_probs_laplace.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_bigram_probs = pickle.load(open('Checkpoints/bigram_probs.pkl', 'rb'))\n",
    "laplace_bigram_probs = pickle.load(open('Checkpoints/bigram_probs_laplace.pkl', 'rb'))\n",
    "kneser_ney_bigram_probs = pickle.load(open('Checkpoints/bigram_probs_kneser.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = pickle.load(open('Checkpoints/vocab.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity_without_smoothing(dataset):   \n",
    "    perplexity_score = 0 \n",
    "    for sentence in dataset:        \n",
    "        sentence = sentence.split()\n",
    "        log_sum = 0\n",
    "        for i in range(len(sentence) - 1):\n",
    "            word1, word2 = sentence[i], sentence[i+1]            \n",
    "            idx1, idx2 = model.vocab.index(word1), model.vocab.index(word2)            \n",
    "            prob = normal_bigram_probs[idx1][idx2]\n",
    "            log_sum += (np.log(prob))*-1\n",
    "        perplexity_score += log_sum/len(sentence)    \n",
    "    perplexity_score/=len(dataset)\n",
    "    return perplexity_score        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity_laplace(dataset):   \n",
    "    perplexity_score = 0 \n",
    "    for sentence in dataset:        \n",
    "        sentence = sentence.split()\n",
    "        log_sum = 0\n",
    "        for i in range(len(sentence) - 1):\n",
    "            word1, word2 = sentence[i], sentence[i+1]            \n",
    "            idx1, idx2 = model.vocab.index(word1), model.vocab.index(word2)            \n",
    "            prob = laplace_bigram_probs[idx1][idx2]\n",
    "            log_sum += (np.log(prob))*-1\n",
    "        perplexity_score += log_sum/len(sentence)    \n",
    "    perplexity_score/=len(dataset)\n",
    "    return perplexity_score        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity_kneser_ney(dataset):   \n",
    "    perplexity_score = 0 \n",
    "    for sentence in dataset:        \n",
    "        sentence = sentence.split()\n",
    "        log_sum = 0\n",
    "        for i in range(len(sentence) - 1):\n",
    "            word1, word2 = sentence[i], sentence[i+1]            \n",
    "            idx1, idx2 = model.vocab.index(word1), model.vocab.index(word2)            \n",
    "            prob = kneser_ney_bigram_probs[idx1][idx2]\n",
    "            log_sum += (np.log(prob))*-1\n",
    "        perplexity_score += log_sum/len(sentence)    \n",
    "    perplexity_score/=len(dataset)\n",
    "    return perplexity_score        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No smoothing perplexity: 2.8340824283984345\n",
      "Laplace perplexity: 8.072952704432762\n",
      "Kneser-ney perplexity: 3.422587385717666\n"
     ]
    }
   ],
   "source": [
    "print(f\"No smoothing perplexity: {perplexity_without_smoothing(dataset)}\")\n",
    "print(f\"Laplace perplexity: {perplexity_laplace(dataset)}\")\n",
    "print(f\"Kneser-ney perplexity: {perplexity_kneser_ney(dataset)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
