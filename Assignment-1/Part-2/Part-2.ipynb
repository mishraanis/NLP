{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from utils import emotion_scores\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLM:\n",
    "    def __init__(self):\n",
    "        self.vocab = set()\n",
    "        self.bigram_counts = defaultdict(lambda: defaultdict(int))\n",
    "        self.unigram_counts = defaultdict(int)\n",
    "        self.bigram_probs = None\n",
    "        self.beta_values = None\n",
    "        self.emotion_dict = {'sadness': 0, 'joy': 1, 'love': 2, 'anger': 3, 'fear': 4, 'surprise': 5}\n",
    "        self.sentence_emotions = []\n",
    "        self.bigram_sentences = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    def learn_from_dataset(self, dataset):\n",
    "        for x, sentence in enumerate(dataset):\n",
    "            emotion = emotion_scores(sentence)\n",
    "            self.sentence_emotions.append(emotion)\n",
    "            tokens = sentence.split()                        \n",
    "            for i in range(len(tokens) - 1):\n",
    "                word1, word2 = tokens[i], tokens[i + 1]\n",
    "                self.vocab.add(word1)\n",
    "                self.vocab.add(word2)\n",
    "                self.bigram_counts[word1][word2] += 1\n",
    "                self.bigram_sentences[word1][word2].append(x)\n",
    "                self.unigram_counts[word1] += 1                            \n",
    "                \n",
    "        self.vocab = list(self.vocab)\n",
    "        print(f\"Vocabulary size: {len(self.vocab)}\")\n",
    "\n",
    "    def calculate_beta_values_sentence(self):  \n",
    "        num_words = len(self.vocab)\n",
    "        self.beta_values_sentence = np.zeros((num_words, num_words, 6))\n",
    "\n",
    "        for i, word1 in tqdm(enumerate(self.vocab)):\n",
    "            if word1 not in self.bigram_counts.keys():\n",
    "                continue\n",
    "            for j, word2 in enumerate(self.vocab):\n",
    "                if word2 not in self.bigram_counts[word1].keys():\n",
    "                    continue\n",
    "                self.beta_values_sentence[i][j] = np.array([np.mean([self.sentence_emotions[sentence][k]['score'] for sentence in self.bigram_sentences[word1][word2]]) for k in range(6)])\n",
    "                \n",
    "\n",
    "    def calculate_beta_values(self):\n",
    "            num_words = len(self.vocab)\n",
    "            self.beta_values = np.zeros((num_words, num_words, 6))\n",
    "            for i, word1 in tqdm(enumerate(self.vocab)):\n",
    "                if word1 not in self.bigram_counts.keys():\n",
    "                    continue\n",
    "                for j, word2 in enumerate(self.vocab):\n",
    "                    if word2 not in self.bigram_counts[word1].keys():\n",
    "                        continue\n",
    "                    emotions = emotion_scores(word1 + \" \" + word2)\n",
    "                    self.beta_values[i][j] = np.array([emotions[k]['score'] for k in range(6)])\n",
    "                    \n",
    "    def calculate_bigram_probs(self):\n",
    "        num_words = len(self.vocab)\n",
    "        self.bigram_probs = np.zeros((num_words, num_words))        \n",
    "        \n",
    "        for i, word1 in tqdm(enumerate(self.vocab)):\n",
    "            for j, word2 in enumerate(self.vocab):\n",
    "                if self.unigram_counts[word1] > 0:\n",
    "                    self.bigram_probs[i][j] = float(self.bigram_counts[word1][word2]) / float(self.unigram_counts[word1])\n",
    "\n",
    "                    \n",
    "    def calculate_bigram_probs_laplace(self):\n",
    "        num_words = len(self.vocab)\n",
    "        self.bigram_probs = np.zeros((num_words, num_words))\n",
    "\n",
    "        for i, word1 in enumerate(self.vocab):\n",
    "            for j, word2 in enumerate(self.vocab):\n",
    "                self.bigram_probs[i][j] = (self.bigram_counts[word1][word2] + 1) / (self.unigram_counts[word1] + num_words)\n",
    "                \n",
    "    \n",
    "    def calculate_bigram_probs_kneser_ney(self, discount=0.75):\n",
    "        num_words = len(self.vocab)\n",
    "        self.bigram_probs = np.zeros((num_words, num_words))\n",
    "\n",
    "        continuation_counts = defaultdict(set)\n",
    "   \n",
    "        for word1, word2_dict in self.bigram_counts.items():\n",
    "            for word2 in word2_dict:\n",
    "                continuation_counts[word2].add(word1)\n",
    "\n",
    "        total_continuations = {word2: len(word1s) for word2, word1s in continuation_counts.items()}\n",
    "\n",
    "        for i, word1 in tqdm(enumerate(self.vocab)):            \n",
    "            for j, word2 in enumerate(self.vocab):\n",
    "                if word2 in total_continuations.keys():\n",
    "                    adjusted_count = max(self.bigram_counts[word1][word2] - discount, 0)\n",
    "                    continuation_prob = total_continuations[word2] / sum(total_continuations.values()) if sum(total_continuations.values()) > 0 else 0\n",
    "                    lower_order_weight = (discount * continuation_prob) / self.unigram_counts[word1] if self.unigram_counts[word1] > 0 else 0\n",
    "\n",
    "                    self.bigram_probs[i][j] = adjusted_count / self.unigram_counts[word1] + lower_order_weight if self.unigram_counts[word1] > 0 else 0                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = open('../Dataset/corpus.txt')\n",
    "dataset = []\n",
    "for i in corpus.readlines():\n",
    "    dataset.append('<SOS> ' + i + ' <EOS>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 5431\n"
     ]
    }
   ],
   "source": [
    "model = BigramLM()\n",
    "model.learn_from_dataset(dataset)\n",
    "pickle.dump(model.vocab, open('Checkpoints/vocab.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.calculate_beta_values_sentence()\n",
    "pickle.dump(model.beta_values_sentence, open('Checkpoints/beta_values_sentence.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.calculate_beta_values()\n",
    "pickle.dump(model.beta_values, open('Checkpoints/beta_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5431it [00:08, 621.91it/s]\n"
     ]
    }
   ],
   "source": [
    "model.calculate_bigram_probs()\n",
    "pickle.dump(model.bigram_probs, open('Checkpoints/bigram_probs.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5431it [24:45,  3.66it/s]\n"
     ]
    }
   ],
   "source": [
    "model.calculate_bigram_probs_kneser_ney()\n",
    "pickle.dump(model.bigram_probs, open('Checkpoints/bigram_probs_kneser.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.calculate_bigram_probs_laplace()\n",
    "pickle.dump(model.bigram_probs, open('Checkpoints/bigram_probs_laplace.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_bigram_probs = pickle.load(open('Checkpoints/bigram_probs.pkl', 'rb'))\n",
    "laplace_bigram_probs = pickle.load(open('Checkpoints/bigram_probs_laplace.pkl', 'rb'))\n",
    "kneser_ney_bigram_probs = pickle.load(open('Checkpoints/bigram_probs_kneser.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = pickle.load(open('Checkpoints/vocab.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity_without_smoothing(dataset):   \n",
    "    perplexity_score = 0 \n",
    "    for sentence in dataset:        \n",
    "        sentence = sentence.split()\n",
    "        log_sum = 0\n",
    "        for i in range(len(sentence) - 1):\n",
    "            word1, word2 = sentence[i], sentence[i+1]            \n",
    "            idx1, idx2 = vocab.index(word1), vocab.index(word2)            \n",
    "            prob = normal_bigram_probs[idx1][idx2]\n",
    "            log_sum += (np.log(prob))*-1\n",
    "        perplexity_score += log_sum/len(sentence)    \n",
    "    perplexity_score/=len(dataset)\n",
    "    return perplexity_score        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity_laplace(dataset):   \n",
    "    perplexity_score = 0 \n",
    "    for sentence in dataset:        \n",
    "        sentence = sentence.split()\n",
    "        log_sum = 0\n",
    "        for i in range(len(sentence) - 1):\n",
    "            word1, word2 = sentence[i], sentence[i+1]            \n",
    "            idx1, idx2 = vocab.index(word1), vocab.index(word2)            \n",
    "            prob = laplace_bigram_probs[idx1][idx2]\n",
    "            log_sum += (np.log(prob))*-1\n",
    "        perplexity_score += log_sum/len(sentence)    \n",
    "    perplexity_score/=len(dataset)\n",
    "    return perplexity_score        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity_kneser_ney(dataset):   \n",
    "    perplexity_score = 0 \n",
    "    for sentence in dataset:        \n",
    "        sentence = sentence.split()\n",
    "        log_sum = 0\n",
    "        for i in range(len(sentence) - 1):\n",
    "            word1, word2 = sentence[i], sentence[i+1]            \n",
    "            idx1, idx2 = vocab.index(word1), vocab.index(word2)            \n",
    "            prob = kneser_ney_bigram_probs[idx1][idx2]\n",
    "            log_sum += (np.log(prob))*-1\n",
    "        perplexity_score += log_sum/len(sentence)    \n",
    "    perplexity_score/=len(dataset)\n",
    "    return perplexity_score        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No smoothing perplexity: 2.8340824283984345\n",
      "Laplace perplexity: 8.072952704432762\n",
      "Kneser-ney perplexity: 3.422587385717666\n"
     ]
    }
   ],
   "source": [
    "print(f\"No smoothing perplexity: {perplexity_without_smoothing(dataset)}\")\n",
    "print(f\"Laplace perplexity: {perplexity_laplace(dataset)}\")\n",
    "print(f\"Kneser-ney perplexity: {perplexity_kneser_ney(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing dataset perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of Test Samples/coeff_1_kneser/gen_fear.txt: 5.96537433869826\n",
      "Perplexity of Test Samples/coeff_1_kneser/gen_joy.txt: 6.183001950338211\n",
      "Perplexity of Test Samples/coeff_1_kneser/gen_love.txt: 8.593746532966685\n",
      "Perplexity of Test Samples/coeff_1_kneser/gen_sadness.txt: 7.941040338677138\n",
      "Perplexity of Test Samples/coeff_1_kneser/gen_anger.txt: 5.828769761761451\n",
      "Perplexity of Test Samples/coeff_1_kneser/gen_surprise.txt: 8.671788996593428\n",
      "Perplexity of all files in Test Samples/coeff_1_kneser/: 7.197286986505866\n",
      "\n",
      "Perplexity of Test Samples/coeff_1_laplace/gen_fear.txt: 7.131570834008292\n",
      "Perplexity of Test Samples/coeff_1_laplace/gen_joy.txt: 7.210130221734684\n",
      "Perplexity of Test Samples/coeff_1_laplace/gen_love.txt: 6.689815629509246\n",
      "Perplexity of Test Samples/coeff_1_laplace/gen_sadness.txt: 7.187539317714028\n",
      "Perplexity of Test Samples/coeff_1_laplace/gen_anger.txt: 6.955970369394107\n",
      "Perplexity of Test Samples/coeff_1_laplace/gen_surprise.txt: 7.689927734659637\n",
      "Perplexity of all files in Test Samples/coeff_1_laplace/: 7.144159017836667\n",
      "\n",
      "Perplexity of Test Samples/coeff_1_no/gen_fear.txt: 3.264470476665161\n",
      "Perplexity of Test Samples/coeff_1_no/gen_joy.txt: 3.370217068559729\n",
      "Perplexity of Test Samples/coeff_1_no/gen_love.txt: 3.4955463008253957\n",
      "Perplexity of Test Samples/coeff_1_no/gen_sadness.txt: 3.459532316020871\n",
      "Perplexity of Test Samples/coeff_1_no/gen_anger.txt: 3.4450220436923233\n",
      "Perplexity of Test Samples/coeff_1_no/gen_surprise.txt: 3.3650088444523463\n",
      "Perplexity of all files in Test Samples/coeff_1_no/: 3.399966175035971\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "all_samples = []\n",
    "dir = 'Test Samples/coeff_1_kneser/'\n",
    "for file in os.listdir(dir):\n",
    "    current_sample = []\n",
    "    f = open(dir + file)\n",
    "    for line in f.readlines():\n",
    "        current_sample.append(line)        \n",
    "    print(f\"Perplexity of {dir + file}: {perplexity_kneser_ney(current_sample)}\")\n",
    "    all_samples.extend(current_sample)\n",
    "print(f\"Perplexity of all files in {dir}: {perplexity_kneser_ney(all_samples)}\")\n",
    "\n",
    "print()\n",
    "\n",
    "all_samples = []\n",
    "dir = 'Test Samples/coeff_1_laplace/'\n",
    "for file in os.listdir(dir):\n",
    "    current_sample = []\n",
    "    f = open(dir + file)\n",
    "    for line in f.readlines():\n",
    "        current_sample.append(line)        \n",
    "    print(f\"Perplexity of {dir + file}: {perplexity_laplace(current_sample)}\")\n",
    "    all_samples.extend(current_sample)\n",
    "print(f\"Perplexity of all files in {dir}: {perplexity_laplace(all_samples)}\")\n",
    "\n",
    "print()\n",
    "\n",
    "all_samples = []\n",
    "dir = 'Test Samples/coeff_1_no/'\n",
    "for file in os.listdir(dir):\n",
    "    current_sample = []\n",
    "    f = open(dir + file)\n",
    "    for line in f.readlines():\n",
    "        current_sample.append(line)        \n",
    "    print(f\"Perplexity of {dir + file}: {perplexity_without_smoothing(current_sample)}\")\n",
    "    all_samples.extend(current_sample)\n",
    "print(f\"Perplexity of all files in {dir}: {perplexity_without_smoothing(all_samples)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 5 bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_top_5(bigram_probs):\n",
    "    vocab = pickle.load(open('Checkpoints/vocab.pkl', 'rb'))\n",
    "    flattened_array = bigram_probs.flatten()\n",
    "    sorted_indices = np.argsort(flattened_array)\n",
    "    top5_indices = sorted_indices[-5:]\n",
    "    top5_indices_2d = np.unravel_index(top5_indices, bigram_probs.shape)\n",
    "    top5_indices_2d = np.column_stack((top5_indices_2d[0], top5_indices_2d[1]))\n",
    "\n",
    "    for i in top5_indices_2d:\n",
    "        print(vocab[i[0]], vocab[i[1]], bigram_probs[i[0]][i[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_bigram_probs = pickle.load(open('Checkpoints/bigram_probs.pkl', 'rb'))\n",
    "laplace_bigram_probs = pickle.load(open('Checkpoints/bigram_probs_laplace.pkl', 'rb'))\n",
    "kneser_ney_bigram_probs = pickle.load(open('Checkpoints/bigram_probs_kneser.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 bigrams before smoothing\n",
      "passionately about 1.0\n",
      "pauses logic 1.0\n",
      "invisible so 1.0\n",
      "forest gump 1.0\n",
      "iming anyone 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 bigrams before smoothing\")\n",
    "calc_top_5(normal_bigram_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 bigrams after laplace smoothing\n",
      "bridezillas at 0.027199591367641426\n",
      "state photos 0.03188720173535792\n",
      "jumping neva 0.03508771929824561\n",
      "state jumping 0.110412147505423\n",
      "bridezillas state 0.2693142638232665\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 bigrams after laplace smoothing\")\n",
    "calc_top_5(laplace_bigram_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 bigrams after kneser-ney smoothing\n",
      "supposed to 0.9183832405280168\n",
      "sort of 0.9565093900961343\n",
      "didn t 0.9583657827447011\n",
      "href http 0.9700023363576185\n",
      "don t 0.9703488828712646\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 bigrams after kneser-ney smoothing\")\n",
    "calc_top_5(kneser_ney_bigram_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
